{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of images in 'apple' folder: 2438\n",
      "Number of images in 'rotten apples' folder: 2930\n"
     ]
    }
   ],
   "source": [
    "# Import necessary libraries\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "from PIL import Image\n",
    "\n",
    "# Set paths for each category\n",
    "dataset_path = 'Fruit And Vegetable Diseases Dataset'\n",
    "apple_folder = os.path.join(dataset_path, 'Apple__Healthy')\n",
    "rotten_apple_folder = os.path.join(dataset_path, 'Apple__Rotten')\n",
    "\n",
    "# Count images in each folder\n",
    "apple_images = os.listdir(apple_folder)\n",
    "rotten_apple_images = os.listdir(rotten_apple_folder)\n",
    "\n",
    "print(f\"Number of images in 'apple' folder: {len(apple_images)}\")\n",
    "print(f\"Number of images in 'rotten apples' folder: {len(rotten_apple_images)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Function to display random sample images from a folder\n",
    "def display_sample_images(folder, title, sample_size=5):\n",
    "    images = os.listdir(folder)\n",
    "    sample_images = random.sample(images, min(sample_size, len(images)))\n",
    "    \n",
    "    plt.figure(figsize=(15, 5))\n",
    "    plt.suptitle(title)\n",
    "    \n",
    "    for i, img_name in enumerate(sample_images):\n",
    "        img_path = os.path.join(folder, img_name)\n",
    "        img = Image.open(img_path)\n",
    "        plt.subplot(1, sample_size, i + 1)\n",
    "        plt.imshow(img)\n",
    "        plt.axis('off')\n",
    "    \n",
    "    plt.show()\n",
    "\n",
    "# Display sample images from each category\n",
    "    # TODO: UNcomment later\n",
    "# display_sample_images(apple_folder, \"Sample Images - Apples\", sample_size=5)\n",
    "# display_sample_images(rotten_apple_folder, \"Sample Images - Rotten Apples\", sample_size=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resizing complete. All images are now 224x224.\n"
     ]
    }
   ],
   "source": [
    "#  Define the target size (e.g., 224x224)\n",
    "target_size = (224, 224)\n",
    "\n",
    "# Create directories to save resized images (optional step to keep original images intact)\n",
    "resized_path = 'Resized_Fruit_And_Vegetable_Diseases_Dataset'\n",
    "os.makedirs(os.path.join(resized_path, 'apple'), exist_ok=True)\n",
    "os.makedirs(os.path.join(resized_path, 'rotten apples'), exist_ok=True)\n",
    "\n",
    "def resize_images(input_folder, output_folder, size):\n",
    "    # Resize and save each image in the specified folder\n",
    "    for img_name in os.listdir(input_folder):\n",
    "        img_path = os.path.join(input_folder, img_name)\n",
    "        try:\n",
    "            img = Image.open(img_path)\n",
    "            img = img.resize(size)  # Resize to target size\n",
    "            if img.mode == 'RGBA':\n",
    "                img = img.convert('RGB')\n",
    "\n",
    "            img.save(os.path.join(output_folder, img_name))  # Save resized image\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing {img_name}: {e}\")\n",
    "\n",
    "# Resize images in both 'apple' and 'rotten apples' folders\n",
    "resize_images(apple_folder, os.path.join(resized_path, 'apple'), target_size)\n",
    "resize_images(rotten_apple_folder, os.path.join(resized_path, 'rotten apples'), target_size)\n",
    "\n",
    "print(\"Resizing complete. All images are now 224x224.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of resized images in 'apple' folder: 2438\n",
      "Number of resized images in 'rotten apples' folder: 2930\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Define paths to the resized folders\n",
    "resized_apple_folder = 'Resized_Fruit_And_Vegetable_Diseases_Dataset/apple'\n",
    "resized_rotten_apple_folder = 'Resized_Fruit_And_Vegetable_Diseases_Dataset/rotten apples'\n",
    "\n",
    "# Count the images in each folder\n",
    "num_apple_images = len(os.listdir(resized_apple_folder))\n",
    "num_rotten_apple_images = len(os.listdir(resized_rotten_apple_folder))\n",
    "\n",
    "# Print the counts\n",
    "print(f\"Number of resized images in 'apple' folder: {num_apple_images}\")\n",
    "print(f\"Number of resized images in 'rotten apples' folder: {num_rotten_apple_images}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data augmentation complete.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "# Define augmentation pipeline using torchvision\n",
    "augmentation = transforms.Compose([\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.RandomRotation(degrees=45),\n",
    "    transforms.RandomResizedCrop(size=(224, 224), scale=(0.8, 1.2)),\n",
    "    transforms.ColorJitter(brightness=0.5, contrast=0.5, saturation=0.5),\n",
    "    transforms.RandomAffine(degrees=0, translate=(0.1, 0.1)),\n",
    "])\n",
    "\n",
    "# Define paths to the resized folders for healthy and rotten apples\n",
    "apple_folder = 'Resized_Fruit_And_Vegetable_Diseases_Dataset/apple'\n",
    "rotten_apple_folder = 'Resized_Fruit_And_Vegetable_Diseases_Dataset/rotten apples'\n",
    "\n",
    "# Number of augmented images to generate per original image\n",
    "augment_per_image = 5\n",
    "\n",
    "# Function to augment images in a given folder and save them back to the same folder\n",
    "def augment_images(folder, augment_pipeline, num_augmentations=5):\n",
    "    for img_name in os.listdir(folder):\n",
    "        img_path = os.path.join(folder, img_name)\n",
    "        try:\n",
    "            img = Image.open(img_path)\n",
    "            for i in range(num_augmentations):\n",
    "                augmented_img = augment_pipeline(img)\n",
    "                augmented_img.save(os.path.join(folder, f\"{img_name.split('.')[0]}_aug_{i}.jpg\"))\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing {img_name}: {e}\")\n",
    "\n",
    "# Apply augmentation to images in both the \"apple\" and \"rotten apples\" folders\n",
    "augment_images(apple_folder, augmentation, augment_per_image)\n",
    "augment_images(rotten_apple_folder, augmentation, augment_per_image)\n",
    "\n",
    "print(\"Data augmentation complete.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of resized images in 'apple' folder: 6248\n",
      "Number of resized images in 'rotten apples' folder: 5965\n"
     ]
    }
   ],
   "source": [
    "# Count the images in each folder\n",
    "num_apple_images = len(os.listdir(resized_apple_folder))\n",
    "num_rotten_apple_images = len(os.listdir(resized_rotten_apple_folder))\n",
    "\n",
    "# Print the counts\n",
    "print(f\"Number of resized images in 'apple' folder: {num_apple_images}\")\n",
    "print(f\"Number of resized images in 'rotten apples' folder: {num_rotten_apple_images}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset split into train, validation, and test sets.\n"
     ]
    }
   ],
   "source": [
    "import shutil\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Paths to the augmented image folders\n",
    "apple_folder = 'Resized_Fruit_And_Vegetable_Diseases_Dataset/apple'\n",
    "rotten_apple_folder = 'Resized_Fruit_And_Vegetable_Diseases_Dataset/rotten apples'\n",
    "\n",
    "# Define paths for the split dataset\n",
    "train_path = 'dataset_split/train'\n",
    "val_path = 'dataset_split/val'\n",
    "test_path = 'dataset_split/test'\n",
    "\n",
    "# Create directories for train, validation, and test sets\n",
    "for split in [train_path, val_path, test_path]:\n",
    "    os.makedirs(os.path.join(split, 'apple'), exist_ok=True)\n",
    "    os.makedirs(os.path.join(split, 'rotten apples'), exist_ok=True)\n",
    "\n",
    "# Function to split and copy images\n",
    "def split_and_copy_images(folder, label):\n",
    "    images = os.listdir(folder)\n",
    "    train_images, temp_images = train_test_split(images, test_size=0.2, random_state=42)  # 80% train, 20% temp\n",
    "    val_images, test_images = train_test_split(temp_images, test_size=0.5, random_state=42)  # Split remaining into 10% val, 10% test\n",
    "    \n",
    "    # Copy images to respective folders\n",
    "    for img_name in train_images:\n",
    "        shutil.copy(os.path.join(folder, img_name), os.path.join(train_path, label, img_name))\n",
    "    for img_name in val_images:\n",
    "        shutil.copy(os.path.join(folder, img_name), os.path.join(val_path, label, img_name))\n",
    "    for img_name in test_images:\n",
    "        shutil.copy(os.path.join(folder, img_name), os.path.join(test_path, label, img_name))\n",
    "\n",
    "# Split and copy images for both categories\n",
    "split_and_copy_images(apple_folder, 'apple')\n",
    "split_and_copy_images(rotten_apple_folder, 'rotten apples')\n",
    "\n",
    "print(\"Dataset split into train, validation, and test sets.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set: 4998 healthy apples, 4772 rotten apples\n",
      "Validation set: 625 healthy apples, 596 rotten apples\n",
      "Test set: 625 healthy apples, 597 rotten apples\n",
      "\n",
      "Total counts:\n",
      "Healthy apples: 6248\n",
      "Rotten apples: 5965\n",
      "Total images: 12213\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Function to count images in a given folder\n",
    "def count_images_in_folder(folder):\n",
    "    apple_count = len(os.listdir(os.path.join(folder, 'apple')))\n",
    "    rotten_apple_count = len(os.listdir(os.path.join(folder, 'rotten apples')))\n",
    "    return apple_count, rotten_apple_count\n",
    "\n",
    "# Count images in each split\n",
    "train_apple, train_rotten = count_images_in_folder(train_path)\n",
    "val_apple, val_rotten = count_images_in_folder(val_path)\n",
    "test_apple, test_rotten = count_images_in_folder(test_path)\n",
    "\n",
    "# Print the results\n",
    "print(f\"Train set: {train_apple} healthy apples, {train_rotten} rotten apples\")\n",
    "print(f\"Validation set: {val_apple} healthy apples, {val_rotten} rotten apples\")\n",
    "print(f\"Test set: {test_apple} healthy apples, {test_rotten} rotten apples\")\n",
    "\n",
    "print(\"\\nTotal counts:\")\n",
    "print(f\"Healthy apples: {train_apple + val_apple + test_apple}\")\n",
    "print(f\"Rotten apples: {train_rotten + val_rotten + test_rotten}\")\n",
    "print(f\"Total images: {train_apple + train_rotten + val_apple + val_rotten + test_apple + test_rotten}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n",
      "Downloading: \"https://download.pytorch.org/models/resnet18-f37072fd.pth\" to /Users/suhanishokeen/.cache/torch/hub/checkpoints/resnet18-f37072fd.pth\n",
      "100%|██████████| 44.7M/44.7M [00:01<00:00, 43.6MB/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss: 0.3576 Acc: 0.8397\n",
      "val Loss: 0.3043 Acc: 0.8624\n",
      "\n",
      "Epoch 2/10\n",
      "----------\n",
      "train Loss: 0.2592 Acc: 0.8904\n",
      "val Loss: 0.1753 Acc: 0.9345\n",
      "\n",
      "Epoch 3/10\n",
      "----------\n",
      "train Loss: 0.2481 Acc: 0.8966\n",
      "val Loss: 0.1561 Acc: 0.9443\n",
      "\n",
      "Epoch 4/10\n",
      "----------\n",
      "train Loss: 0.2278 Acc: 0.9026\n",
      "val Loss: 0.1819 Acc: 0.9312\n",
      "\n",
      "Epoch 5/10\n",
      "----------\n",
      "train Loss: 0.2229 Acc: 0.9044\n",
      "val Loss: 0.1771 Acc: 0.9263\n",
      "\n",
      "Epoch 6/10\n",
      "----------\n",
      "train Loss: 0.2127 Acc: 0.9093\n",
      "val Loss: 0.1900 Acc: 0.9197\n",
      "\n",
      "Epoch 7/10\n",
      "----------\n",
      "train Loss: 0.2285 Acc: 0.9048\n",
      "val Loss: 0.1363 Acc: 0.9484\n",
      "\n",
      "Epoch 8/10\n",
      "----------\n",
      "train Loss: 0.2062 Acc: 0.9137\n",
      "val Loss: 0.1547 Acc: 0.9402\n",
      "\n",
      "Epoch 9/10\n",
      "----------\n",
      "train Loss: 0.2055 Acc: 0.9156\n",
      "val Loss: 0.1470 Acc: 0.9394\n",
      "\n",
      "Epoch 10/10\n",
      "----------\n",
      "train Loss: 0.2055 Acc: 0.9141\n",
      "val Loss: 0.1365 Acc: 0.9484\n",
      "\n",
      "Training complete.\n",
      "Test Accuracy: 0.9615\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms, models\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "# 1. Define Data Augmentation and Normalization\n",
    "data_transforms = {\n",
    "    'train': transforms.Compose([\n",
    "        transforms.RandomResizedCrop(224),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ]),\n",
    "    'val': transforms.Compose([\n",
    "        transforms.Resize(256),\n",
    "        transforms.CenterCrop(224),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ]),\n",
    "}\n",
    "\n",
    "# Load the dataset splits\n",
    "data_dir = 'dataset_split'\n",
    "image_datasets = {x: datasets.ImageFolder(os.path.join(data_dir, x), data_transforms[x])\n",
    "                  for x in ['train', 'val']}\n",
    "dataloaders = {x: DataLoader(image_datasets[x], batch_size=32, shuffle=True, num_workers=4)\n",
    "               for x in ['train', 'val']}\n",
    "dataset_sizes = {x: len(image_datasets[x]) for x in ['train', 'val']}\n",
    "class_names = image_datasets['train'].classes\n",
    "\n",
    "# 2. Load ResNet18 Pre-trained Model and Modify the Final Layer\n",
    "model = models.resnet18(pretrained=True)\n",
    "\n",
    "# Freeze all layers except the final one\n",
    "for param in model.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "# Modify the final layer for binary classification\n",
    "num_features = model.fc.in_features\n",
    "model.fc = nn.Linear(num_features, 2)  # 2 classes: \"rotten\" and \"non-rotten\"\n",
    "\n",
    "# Move the model to GPU if available\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = model.to(device)\n",
    "\n",
    "# 3. Define Loss Function, Optimizer, and Scheduler\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.fc.parameters(), lr=0.001)\n",
    "scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=7, gamma=0.1)\n",
    "\n",
    "# 4. Train the Model\n",
    "num_epochs = 10\n",
    "for epoch in range(num_epochs):\n",
    "    print(f'Epoch {epoch+1}/{num_epochs}')\n",
    "    print('-' * 10)\n",
    "    \n",
    "    for phase in ['train', 'val']:\n",
    "        if phase == 'train':\n",
    "            model.train()\n",
    "        else:\n",
    "            model.eval()\n",
    "        \n",
    "        running_loss = 0.0\n",
    "        running_corrects = 0\n",
    "\n",
    "        # Iterate over data\n",
    "        for inputs, labels in dataloaders[phase]:\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            # Forward pass\n",
    "            with torch.set_grad_enabled(phase == 'train'):\n",
    "                outputs = model(inputs)\n",
    "                _, preds = torch.max(outputs, 1)\n",
    "                loss = criterion(outputs, labels)\n",
    "                \n",
    "                # Backward pass and optimization in training phase\n",
    "                if phase == 'train':\n",
    "                    loss.backward()\n",
    "                    optimizer.step()\n",
    "            \n",
    "            running_loss += loss.item() * inputs.size(0)\n",
    "            running_corrects += torch.sum(preds == labels.data)\n",
    "        \n",
    "        # Adjust learning rate\n",
    "        if phase == 'train':\n",
    "            scheduler.step()\n",
    "        \n",
    "        epoch_loss = running_loss / dataset_sizes[phase]\n",
    "        epoch_acc = running_corrects.double() / dataset_sizes[phase]\n",
    "        \n",
    "        print(f'{phase} Loss: {epoch_loss:.4f} Acc: {epoch_acc:.4f}')\n",
    "    \n",
    "    print()\n",
    "\n",
    "print(\"Training complete.\")\n",
    "\n",
    "# 5. Evaluate on Test Set\n",
    "test_dataset = datasets.ImageFolder(os.path.join(data_dir, 'test'), data_transforms['val'])\n",
    "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False, num_workers=4)\n",
    "model.eval()\n",
    "running_corrects = 0\n",
    "\n",
    "with torch.no_grad():\n",
    "    for inputs, labels in test_loader:\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "        outputs = model(inputs)\n",
    "        _, preds = torch.max(outputs, 1)\n",
    "        running_corrects += torch.sum(preds == labels.data)\n",
    "\n",
    "test_acc = running_corrects.double() / len(test_dataset)\n",
    "print(f'Test Accuracy: {test_acc:.4f}')\n",
    "\n",
    "# Save the model\n",
    "torch.save(model.state_dict(), 'apple_classifier_resnet18.pth')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Training and Validation Summary\n",
    "\n",
    "This analysis covers the training and validation performance of a ResNet18 model fine-tuned to classify apples as \"rotten\" or \"non-rotten\" over 10 epochs.\n",
    "\n",
    "#### Key Results\n",
    "- **Initial Epoch**: The model starts with a train accuracy of 83.97% and validation accuracy of 86.24%. The close training and validation losses suggest effective generalization from the start.\n",
    "- **Epochs 2-6**: Both training and validation accuracy steadily improve, reaching 90%+ as the model learns more meaningful features.\n",
    "- **Final Epoch (10)**: The model achieves a train accuracy of 91.41% and validation accuracy of 94.84%, with stable, low losses, indicating minimal overfitting.\n",
    "\n",
    "#### Test Set Evaluation\n",
    "- **Test Accuracy**: 96.15%, confirming that the model generalizes well to unseen data.\n",
    "\n",
    "#### Summary\n",
    "The model demonstrated consistent learning with minimal overfitting and reached 96.15% accuracy on the test set. This high performance indicates readiness for deployment or further fine-tuning, achieving reliable classification of apple quality."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
